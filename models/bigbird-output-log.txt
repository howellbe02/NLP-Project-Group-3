(base) PS C:\Users\benja\OneDrive\Documents\GitHub\NLP-Project-Group-3\models>  c:; cd 'c:\Users\benja\OneDrive\Documents\GitHub\NLP-Project-Group-3\models'; & 'c:\Users\benja\.conda\envs\torchpip\python.exe' 'c:\Users\benja\.vscode\extensions\ms-python.debugpy-2025.6.0-win32-x64\bundled\libs\debugpy\launcher' '50936' '--' 'C:\Users\benja\OneDrive\Documents\GitHub\NLP-Project-Group-3\models\train_bigbird.py' 
Using device: cuda
Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\benja\.conda\envs\torchpip\lib\site-packages\torch\nn\modules\module.py:1329: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\c10/cuda/CUDAAllocatorConfig.h:28.)
  return t.to(
C:\Users\benja\OneDrive\Documents\GitHub\NLP-Project-Group-3\models\train_bigbird.py:131: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
{'loss': 1.1787, 'grad_norm': 5.471551418304443, 'learning_rate': 4.9040000000000005e-05, 'epoch': 0.2}
{'loss': 1.195, 'grad_norm': 2.163818597793579, 'learning_rate': 4.804e-05, 'epoch': 0.4}                                                                                           
{'loss': 1.1294, 'grad_norm': 5.478771686553955, 'learning_rate': 4.7040000000000004e-05, 'epoch': 0.6}                                                                             
{'loss': 1.2221, 'grad_norm': 3.45755672454834, 'learning_rate': 4.604e-05, 'epoch': 0.8}                                                                                           
{'loss': 1.1498, 'grad_norm': inf, 'learning_rate': 4.504e-05, 'epoch': 1.0}                                                                                                        
{'eval_loss': 1.176303744316101, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 33.2649, 'eval_samples_per_second': 3.006, 'eval_steps_per_second': 0.752, 'epoch': 1.0}
{'loss': 1.1662, 'grad_norm': 7.231284141540527, 'learning_rate': 4.4080000000000005e-05, 'epoch': 1.2}                                                                             
{'loss': 1.1829, 'grad_norm': 4.592767715454102, 'learning_rate': 4.308e-05, 'epoch': 1.4}
{'loss': 1.2543, 'grad_norm': 2.8034543991088867, 'learning_rate': 4.2080000000000004e-05, 'epoch': 1.6}                                                                            
{'loss': 1.025, 'grad_norm': 2.0330145359039307, 'learning_rate': 4.108e-05, 'epoch': 1.8}                                                                                          
{'loss': 1.2245, 'grad_norm': 2.967477321624756, 'learning_rate': 4.008e-05, 'epoch': 2.0}                                                                                          
{'eval_loss': 1.126010775566101, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 31.2884, 'eval_samples_per_second': 3.196, 'eval_steps_per_second': 0.799, 'epoch': 2.0}
{'loss': 1.1279, 'grad_norm': 3.1531121730804443, 'learning_rate': 3.908e-05, 'epoch': 2.2}                                                                                         
{'loss': 1.1826, 'grad_norm': 3.082928419113159, 'learning_rate': 3.808e-05, 'epoch': 2.4}
{'loss': 1.0875, 'grad_norm': 1.8190701007843018, 'learning_rate': 3.7080000000000004e-05, 'epoch': 2.6}                                                                            
{'loss': 1.2265, 'grad_norm': 2.1261649131774902, 'learning_rate': 3.608e-05, 'epoch': 2.8}                                                                                         
{'loss': 1.1519, 'grad_norm': 1.7010828256607056, 'learning_rate': 3.508e-05, 'epoch': 3.0}                                                                                         
{'eval_loss': 1.1170361042022705, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 32.6965, 'eval_samples_per_second': 3.058, 'eval_steps_per_second': 0.765, 'epoch': 3.0}
{'loss': 1.1205, 'grad_norm': 2.7098615169525146, 'learning_rate': 3.408e-05, 'epoch': 3.2}                                                                                         
{'loss': 1.1896, 'grad_norm': 1.6043000221252441, 'learning_rate': 3.308e-05, 'epoch': 3.4}
{'loss': 1.1633, 'grad_norm': 2.9347267150878906, 'learning_rate': 3.208e-05, 'epoch': 3.6}                                                                                         
{'loss': 1.1181, 'grad_norm': 1.7197141647338867, 'learning_rate': 3.108e-05, 'epoch': 3.8}                                                                                         
{'loss': 1.1859, 'grad_norm': 4.529532432556152, 'learning_rate': 3.0080000000000003e-05, 'epoch': 4.0}                                                                             
{'eval_loss': 1.1152539253234863, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 32.0865, 'eval_samples_per_second': 3.117, 'eval_steps_per_second': 0.779, 'epoch': 4.0}
{'loss': 1.076, 'grad_norm': 2.8863985538482666, 'learning_rate': 2.9080000000000003e-05, 'epoch': 4.2}                                                                             
{'loss': 1.1638, 'grad_norm': 3.3628454208374023, 'learning_rate': 2.8080000000000002e-05, 'epoch': 4.4}
{'loss': 1.2245, 'grad_norm': 3.143709182739258, 'learning_rate': 2.7079999999999998e-05, 'epoch': 4.6}                                                                             
{'loss': 1.1341, 'grad_norm': 2.4413809776306152, 'learning_rate': 2.6079999999999998e-05, 'epoch': 4.8}                                                                            
{'loss': 1.1236, 'grad_norm': 2.901501178741455, 'learning_rate': 2.5080000000000004e-05, 'epoch': 5.0}                                                                             
{'eval_loss': 1.1140234470367432, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 29.7872, 'eval_samples_per_second': 3.357, 'eval_steps_per_second': 0.839, 'epoch': 5.0}
{'loss': 1.1163, 'grad_norm': 3.7756459712982178, 'learning_rate': 2.408e-05, 'epoch': 5.2}                                                                                         
{'loss': 1.1044, 'grad_norm': 5.649552822113037, 'learning_rate': 2.3080000000000003e-05, 'epoch': 5.4}
{'loss': 1.1719, 'grad_norm': 5.052567005157471, 'learning_rate': 2.2080000000000002e-05, 'epoch': 5.6}                                                                             
{'loss': 1.1918, 'grad_norm': 3.184429168701172, 'learning_rate': 2.1079999999999998e-05, 'epoch': 5.8}                                                                             
{'loss': 1.1766, 'grad_norm': 3.6160261631011963, 'learning_rate': 2.008e-05, 'epoch': 6.0}                                                                                         
{'eval_loss': 1.1194872856140137, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 31.0307, 'eval_samples_per_second': 3.223, 'eval_steps_per_second': 0.806, 'epoch': 6.0}
{'loss': 1.1771, 'grad_norm': 2.865043878555298, 'learning_rate': 1.908e-05, 'epoch': 6.2}                                                                                          
{'loss': 1.1249, 'grad_norm': 2.8238937854766846, 'learning_rate': 1.808e-05, 'epoch': 6.4}
{'loss': 1.1543, 'grad_norm': 5.188692569732666, 'learning_rate': 1.7080000000000002e-05, 'epoch': 6.6}                                                                             
{'loss': 1.1479, 'grad_norm': 5.2025041580200195, 'learning_rate': 1.6080000000000002e-05, 'epoch': 6.8}                                                                            
{'loss': 1.1024, 'grad_norm': 1.7708581686019897, 'learning_rate': 1.508e-05, 'epoch': 7.0}                                                                                         
{'eval_loss': 1.1340185403823853, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 31.4708, 'eval_samples_per_second': 3.178, 'eval_steps_per_second': 0.794, 'epoch': 7.0}
{'loss': 1.102, 'grad_norm': 5.332732677459717, 'learning_rate': 1.408e-05, 'epoch': 7.2}                                                                                           
{'loss': 1.1692, 'grad_norm': 2.9954068660736084, 'learning_rate': 1.308e-05, 'epoch': 7.4}
{'loss': 1.2285, 'grad_norm': 3.680070400238037, 'learning_rate': 1.2080000000000001e-05, 'epoch': 7.6}                                                                             
{'loss': 1.1372, 'grad_norm': 2.2514281272888184, 'learning_rate': 1.108e-05, 'epoch': 7.8}                                                                                         
{'loss': 1.0878, 'grad_norm': 2.515371084213257, 'learning_rate': 1.008e-05, 'epoch': 8.0}                                                                                          
{'eval_loss': 1.124941349029541, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 29.7041, 'eval_samples_per_second': 3.367, 'eval_steps_per_second': 0.842, 'epoch': 8.0}
{'loss': 1.0604, 'grad_norm': 2.35188364982605, 'learning_rate': 9.080000000000001e-06, 'epoch': 8.2}                                                                               
{'loss': 1.1175, 'grad_norm': 1.7913906574249268, 'learning_rate': 8.08e-06, 'epoch': 8.4}
{'loss': 1.1652, 'grad_norm': 2.8431766033172607, 'learning_rate': 7.080000000000001e-06, 'epoch': 8.6}                                                                             
{'loss': 1.2629, 'grad_norm': 3.462404727935791, 'learning_rate': 6.08e-06, 'epoch': 8.8}                                                                                           
{'loss': 1.1251, 'grad_norm': 2.7341225147247314, 'learning_rate': 5.08e-06, 'epoch': 9.0}                                                                                          
{'eval_loss': 1.1226806640625, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 31.0898, 'eval_samples_per_second': 3.216, 'eval_steps_per_second': 0.804, 'epoch': 9.0}
{'loss': 1.2002, 'grad_norm': 3.3494982719421387, 'learning_rate': 4.080000000000001e-06, 'epoch': 9.2}                                                                             
{'loss': 1.1135, 'grad_norm': 2.7757785320281982, 'learning_rate': 3.08e-06, 'epoch': 9.4}
{'loss': 1.1012, 'grad_norm': 1.8285434246063232, 'learning_rate': 2.08e-06, 'epoch': 9.6}                                                                                          
{'loss': 1.1594, 'grad_norm': 1.9230026006698608, 'learning_rate': 1.08e-06, 'epoch': 9.8}                                                                                          
{'loss': 1.1053, 'grad_norm': 3.123006582260132, 'learning_rate': 8e-08, 'epoch': 10.0}
{'eval_loss': 1.1215331554412842, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 32.4306, 'eval_samples_per_second': 3.084, 'eval_steps_per_second': 0.771, 'epoch': 10.0}
{'train_runtime': 6460.0199, 'train_samples_per_second': 0.774, 'train_steps_per_second': 0.193, 'train_loss': 1.15213056640625, 'epoch': 10.0}                                     
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [1:47:40<00:00,  5.17s/it]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]
Evaluation results:
 {'eval_loss': 1.176303744316101, 'eval_accuracy': 0.43, 'eval_f1': 0.15034965034965034, 'eval_runtime': 32.299, 'eval_samples_per_second': 3.096, 'eval_steps_per_second': 0.774, 'epoch': 10.0}